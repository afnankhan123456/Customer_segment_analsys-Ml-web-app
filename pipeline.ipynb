{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc6fdbd0-2f8b-4d84-a665-79ad65a92819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6a9b3b5-fe43-4f88-8059-ad932ccc0e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"smartseg_cleaned.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a641121-3faa-4bd7-af2e-c80a20493811",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(df)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48660c93-5743-4396-8b1b-97781bbd3c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio: [9.98020230e-01 8.27557376e-04 2.91180052e-04]\n",
      "Total variance captured: 99.91 %\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=3)\n",
    "pca_data = pca.fit_transform(X_scaled)\n",
    "\n",
    "pca_df = pd.DataFrame(pca_data, columns=['PCA1', 'PCA2', 'PCA3'])\n",
    "\n",
    "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "print(\"Total variance captured:\", round(sum(pca.explained_variance_ratio_) * 100, 2), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f940fea7-f460-44c8-a924-1d73884c7912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Auto-selected (adjusted) eps: 3.87\n"
     ]
    }
   ],
   "source": [
    "def find_best_eps(X, min_samples=5):\n",
    "    neigh = NearestNeighbors(n_neighbors=min_samples)\n",
    "    nbrs = neigh.fit(X)\n",
    "    distances, _ = nbrs.kneighbors(X)\n",
    "    distances = np.sort(distances[:, -1])\n",
    "    diffs = np.diff(distances)\n",
    "    eps = distances[np.argmax(diffs)]\n",
    "    return round(float(eps), 2)\n",
    "    \n",
    "best_eps = find_best_eps(pca_df, min_samples=5)\n",
    "if best_eps < 1 or best_eps > 10:\n",
    "    best_eps = 3  \n",
    "print(f\"üîç Auto-selected (adjusted) eps: {best_eps}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "682d403e-c4a4-4ab0-87e6-a44ce271c4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster counts:\n",
      "segment_id\n",
      "-1       1\n",
      " 0    9333\n",
      " 1     668\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total clusters (excluding noise): 2\n",
      "Total noise points: 1\n"
     ]
    }
   ],
   "source": [
    "dbscan = DBSCAN(eps=best_eps, min_samples=5)\n",
    "labels = dbscan.fit_predict(pca_df)   \n",
    "\n",
    "df['segment_id'] = labels\n",
    "df['outlier_flag'] = (labels == -1)\n",
    "\n",
    "cluster_counts = df['segment_id'].value_counts().sort_index()\n",
    "\n",
    "num_clusters = len([c for c in cluster_counts.index if c != -1])\n",
    "\n",
    "num_noise = cluster_counts.get(-1, 0)\n",
    "\n",
    "print(\"\\nCluster counts:\")\n",
    "print(cluster_counts)\n",
    "print(f\"\\nTotal clusters (excluding noise): {num_clusters}\")\n",
    "print(f\"Total noise points: {num_noise}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "744e931c-b5bf-4d07-94f4-9e04d27f9f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß≠ Silhouette Score: 0.543\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "mask = labels != -1\n",
    "if len(set(labels[mask])) > 1:\n",
    "    score = silhouette_score(X_scaled[mask], labels[mask])\n",
    "    print(f\"üß≠ Silhouette Score: {score:.3f}\")\n",
    "else:\n",
    "    score = None\n",
    "    print(\"‚ö†Ô∏è Clusters too small or only noise present ‚Äî silhouette score unavailable.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e33361d-3f8d-4431-a5d5-dac2bc41fb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model pipeline saved successfully!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', scaler),   \n",
    "    ('pca', pca),         \n",
    "    ('dbscan', dbscan)    \n",
    "])\n",
    "\n",
    "joblib.dump(pipeline, 'customer_segmentation.pkl')\n",
    "print(\"‚úÖ Model pipeline saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
